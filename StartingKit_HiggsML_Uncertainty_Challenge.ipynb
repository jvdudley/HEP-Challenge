{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Kit - FAIR UNIVERSE: HIGGSML UNCERTAINTY CHALLENGE\n",
    "\n",
    "For Overview and Decsiptions of the competition, please visit the competition page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Setup\n",
    "\n",
    "#### ⚠️ Note:\n",
    "If you are running this starting kit locally, you may want to use a dedicated conda env.  \n",
    "[Instructions to setup a conda env](https://github.com/FAIR-Universe/HEP-Challenge/tree/master/conda)\n",
    "\n",
    "#### ⚠️ Note:\n",
    "If you are running this starting kit on MAC OS, you may want to check and install `libomp` package. \n",
    "This package is needed to run xgboost model. Follow the steps below for complete installations.\n",
    "\n",
    "If still you are facing problems with XGBoost, you can uninstall the current xgboost and install py-xgboost in your environment\n",
    "\n",
    "Uninstall XGBoost\n",
    "```\n",
    "pip uninstall xgboost\n",
    "```\n",
    "\n",
    "Install py-xgboost using conda\n",
    "```\n",
    "conda install py-xgboost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`COLAB` determines whether this notebook is running on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLAB = 'google.colab' in str(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    # clone github repo\n",
    "    !git clone --depth 1 https://github.com/FAIR-Universe/HEP-Challenge.git\n",
    "\n",
    "    # move to the HEP starting kit folder\n",
    "    %cd HEP-Challenge/\n",
    "\n",
    "    # Install required packages\n",
    "    # %pip install -r conda/requirements.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dummy_Submission\n",
    "By this point you should have a clone of the repo which contains `HiggsML_Dummy_Submission.zip` which you can submit to the Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sys import path\n",
    "from zipfile import ZipFile, ZIP_DEFLATED\n",
    "from contextlib import closing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "root_dir = os.getcwd()\n",
    "print(\"Root directory is\", root_dir)\n",
    "\n",
    "# The directory of the input data\n",
    "input_dir = os.path.join(root_dir, \"input_data\")\n",
    "\n",
    "# The directory where results and other outputs from the participant's code will be written\n",
    "output_dir = os.path.join(root_dir, \"sample_result_submission\") \n",
    "\n",
    "# The directory of the ingestion program \n",
    "program_dir = os.path.join(root_dir, \"ingestion_program\") \n",
    "\n",
    "# The directory of the scoring program\n",
    "score_dir = os.path.join(root_dir, \"scoring_program\")\n",
    "\n",
    "# Add the directory to the path\n",
    "path.append(program_dir) \n",
    "path.append(score_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from systematics import systematics # import the systematics function from the ingestion program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Data\n",
    "***\n",
    "\n",
    "⚠️ Note:\n",
    "\n",
    "By default the repository has a sample dataset at [input_data](/input_data/). This is a small sample data is for demonstration only to get a view of what the data looks like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Training and inference you may want to use the much Bigger public dataset. For this set `USE_PUBLIC_DATASET` to `True` and the code below uses the  `Neurips2024_public_dataset()` funtion in the `dataset` module to download and read the public dataset. else the code loads the small sample data for quick execution of this notebook\n",
    "\n",
    "\n",
    "⚠️ Note:\n",
    "\n",
    "If you have already downloaded the public_data from the competition website, make sure that it is placed in the right folder `HEP-Challenge/` so that you don't download it again. Setting `USE_PUBLIC_DATASET` to `True` will download the public_data if not found in the `HEP-Challenge` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_PUBLIC_DATASET = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`USE_PUBLIC_DATASET` determines whether to use a public dataset provided for the participants or use a small subset of the data for quick execution of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Data # import the Data class from the ingestion program\n",
    "\n",
    "if USE_PUBLIC_DATASET:\n",
    "    from datasets import Neurips2024_public_dataset as public_dataset\n",
    "    data = public_dataset()\n",
    "else:\n",
    "    data = Data(input_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function loads the downloaded data in the public_data folder or downloads the data from codabench using `wget` in the absence of the downloaded data, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load train set\n",
    "data.load_train_set() # load the training set to memory, this may take a few seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test sets\n",
    "data.load_test_set() # load the test set to memory, this may take a few seconds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Visualize\n",
    "***\n",
    "The purpose of the `Dataset_visualise` class is to visulaise the training dataset,\n",
    "data is the dictionary of different fields like dataframe, label, weights etc. upon initiallisation you will see a table of these fields\n",
    "\n",
    "Initialisation you can give a list a columns of Data you are interested to have plots for. If no inputs are given then all the columns of the DataFrame are taken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import visualization as viz\n",
    "\n",
    "data_vis = data.get_train_set()\n",
    " \n",
    "# when No systematics parameters are passed, the systematics function will return the original dataset with post process cuts\n",
    "data_vis = systematics(data_vis) \n",
    "train_visualize = viz.Dataset_visualise(\n",
    "    data_set=data_vis,\n",
    "    columns=[\n",
    "        \"PRI_met\",\n",
    "        \"PRI_had_pt\",\n",
    "        \"DER_mass_vis\",\n",
    "        \"DER_mass_transverse_met_lep\",\n",
    "        \"DER_deltar_had_lep\",\n",
    "\n",
    "    ],\n",
    "    name=\"Train Set\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `examine_dataset` methods give you more general infomation as tables to give an idea of the general nature of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.examine_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms\n",
    "The `histogram_dataset` method gives a set of histograms (for the columns defined before)\n",
    "It provides insights into the range and frequency of values for a specific feature. By analyzing the histogram, we can identify any patterns or anomalies in the data. This helps in understanding the underlying distribution and making informed decisions during the data analysis process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show data summary\n",
    "train_visualize.histogram_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacked Histogram\n",
    "\n",
    "The stacked histogram is a visualization technique used to display the distribution of categories within a dataset for a perticular feature. It is particularly useful when comparing the distribution of different groups or classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize.stacked_histogram(\"PRI_jet_leading_eta\",mu_hat=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize.pair_plots(sample_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "syst_train_data = data.get_syst_train_set(tes=0.9, dopostprocess=True) # you can use other systematics like jes, softmet, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize.histogram_syst(syst_train_data['data'],syst_train_data['weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For event vise plots we want sytematics plots without without post process cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vis = data.get_train_set()\n",
    "# when No systematics parameters are passed, and dopostprocess is false .This mean only derived quantities are calculated\n",
    "data_vis = systematics(data_vis, dopostprocess=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize = viz.Dataset_visualise(\n",
    "    data_set=data_vis,\n",
    "    columns=[\n",
    "        \"PRI_met\",\n",
    "        \"PRI_had_pt\",\n",
    "        \"DER_mass_vis\",\n",
    "        \"DER_mass_transverse_met_lep\",\n",
    "        \"DER_deltar_had_lep\",\n",
    "\n",
    "    ],\n",
    "    name=\"Train Set\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_syst = data.get_syst_train_set(tes=0.9) # you can use other systematics like jes, softmet, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_visualize.event_vise_syst(data_syst['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Program\n",
    "***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from ingestion import Ingestion\n",
    "\n",
    "ingestion = Ingestion(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## MODEL\n",
    "***\n",
    "* For the competition model should be defined as a class and saved a file called model.py.\n",
    "* Two models are available in this notebook one is a ML + counting method.\n",
    "    1. Histogram + Likelihood method - set `USE_INTERNAL_HISTOGRAM_MODEL` to true to use this model\n",
    "    2. ML + counting method - set `USE_INTERNAL_ML_MODEL` to true to use it\n",
    "        * The same model is available in [simple_stat_only_model](/simple_stat_only_model/), - set `USE_SIMPLE_STAT_ONLY_MODEL` to `True` to use this model\n",
    "* A slightly more advance model which can work with 1 systematics is available in [simple_one_syst_model](/simple_one_syst_model/) \n",
    "    * set `USE_SIMPLE_ONE_SYST_MODEL` to `True` to use this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_INTERNAL_HISTOGRAM_MODEL = True\n",
    "\n",
    "USE_SIMPLE_STAT_ONLY_MODEL = False\n",
    "USE_SIMPLE_ONE_SYST_MODEL = False\n",
    "USE_INTERNAL_ML_MODEL = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notice when you External Models its imported into the notebook*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_SIMPLE_STAT_ONLY_MODEL:\n",
    "    submission_dir = os.path.join(root_dir, \"simple_stat_only_model\")\n",
    "    path.append(submission_dir)\n",
    "    from model import Model\n",
    "    \n",
    "elif USE_SIMPLE_ONE_SYST_MODEL:\n",
    "    submission_dir = os.path.join(root_dir, \"simple_one_syst_model\")\n",
    "    path.append(submission_dir)\n",
    "    from model import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are defining a bunch a helper function for the `Model` class to do statistics and data splting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `calculate_saved_info` Function\n",
    "\n",
    "Calculates `saved_info` for \"mu\" computation from a model and training data. \n",
    "\n",
    "- **Inputs**:\n",
    "  - `model`: Predictive model.\n",
    "  - `train_set`: Dictionary with training data and labels.\n",
    "  - `file_path`: Optional path to save the results (default is \"saved_info.pkl\").\n",
    "\n",
    "- **Returns**: Dictionary with calculated `beta` and `gamma`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_INTERNAL_ML_MODEL:\n",
    "    def calculate_saved_info(model, train_set):\n",
    "\n",
    "\n",
    "        score = model.predict(train_set[\"data\"])\n",
    "\n",
    "        print(\"score shape before threshold\", score.shape)\n",
    "\n",
    "        score = score.flatten() > 0.5\n",
    "        score = score.astype(int)\n",
    "\n",
    "        label = train_set[\"labels\"]\n",
    "\n",
    "        print(\"score shape after threshold\", score.shape)\n",
    "\n",
    "        gamma = np.sum(train_set[\"weights\"] * score * label) + 0.1\n",
    "\n",
    "        beta = np.sum(train_set[\"weights\"] * score * (1 - label)) - 0.1\n",
    "\n",
    "        saved_info = {\"beta\": beta, \"gamma\": gamma}\n",
    "\n",
    "        print(\"saved_info\", saved_info)\n",
    "\n",
    "        return saved_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `compute_mu` Function\n",
    "\n",
    "Calculates \"mu\" and its uncertainties from scores and weights. It uses a dictionary for additional parameters. \n",
    "\n",
    "- **Inputs**:\n",
    "  - `score`: Array of scores.\n",
    "  - `weight`: Array of weights.\n",
    "  - `saved_info`: Dictionary with \"beta\" and \"gamma\".\n",
    "\n",
    "- **Returns**: A dictionary with \"mu_hat\", \"del_mu_stat\", \"del_mu_sys\", and \"del_mu_tot\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if USE_INTERNAL_ML_MODEL:\n",
    "    def compute_mu(score, weight, saved_info):\n",
    "\n",
    "        score = score.flatten() > 0.5\n",
    "        score = score.astype(int)\n",
    "\n",
    "        mu = (np.sum(score * weight) - saved_info[\"beta\"]) / saved_info[\"gamma\"]\n",
    "        del_mu_stat = (\n",
    "            np.sqrt(saved_info[\"beta\"] + saved_info[\"gamma\"]) / saved_info[\"gamma\"]\n",
    "        )\n",
    "        del_mu_sys = abs(0.1 * mu)\n",
    "        del_mu_tot = (1 / 2) * np.sqrt(del_mu_stat**2 + del_mu_sys**2)\n",
    "\n",
    "        return {\n",
    "            \"mu_hat\": mu,\n",
    "            \"del_mu_stat\": del_mu_stat,\n",
    "            \"del_mu_sys\": del_mu_sys,\n",
    "            \"del_mu_tot\": del_mu_tot,\n",
    "        }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a custom `train_test_split()` build around the sklearn train_test_slipt. This is so it works well with the dictionary setting we have and as a bonus also does reweighting which is essential for getting the statistics right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
    "\n",
    "def train_test_split(data_set, test_size=0.2, random_state=42, reweight=False):\n",
    "\n",
    "    data = data_set[\"data\"].copy()\n",
    "    train_set = {}\n",
    "    test_set = {}\n",
    "    full_size = len(data)\n",
    "\n",
    "    print(f\"Full size of the data is {full_size}\")\n",
    "\n",
    "    for key in data_set.keys():\n",
    "        if (key != \"data\") and (key != \"settings\"):\n",
    "            data[key] = np.array(data_set[key])\n",
    "\n",
    "    train_data, test_data = sk_train_test_split(\n",
    "        data, test_size=test_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    for key in data_set.keys():\n",
    "        if (key != \"data\") and (key != \"settings\"):\n",
    "            train_set[key] = np.array(train_data.pop(key))\n",
    "            test_set[key] = np.array(test_data.pop(key))\n",
    "\n",
    "    train_set[\"data\"] = train_data\n",
    "    test_set[\"data\"] = test_data\n",
    "\n",
    "    if reweight is True:\n",
    "        signal_weight = np.sum(data_set[\"weights\"][data_set[\"labels\"] == 1])\n",
    "        background_weight = np.sum(data_set[\"weights\"][data_set[\"labels\"] == 0])\n",
    "        signal_weight_train = np.sum(train_set[\"weights\"][train_set[\"labels\"] == 1])\n",
    "        background_weight_train = np.sum(train_set[\"weights\"][train_set[\"labels\"] == 0])\n",
    "        signal_weight_test = np.sum(test_set[\"weights\"][test_set[\"labels\"] == 1])\n",
    "        background_weight_test = np.sum(test_set[\"weights\"][test_set[\"labels\"] == 0])\n",
    "\n",
    "        train_set[\"weights\"][train_set[\"labels\"] == 1] = train_set[\"weights\"][\n",
    "            train_set[\"labels\"] == 1\n",
    "        ] * (signal_weight / signal_weight_train)\n",
    "        test_set[\"weights\"][test_set[\"labels\"] == 1] = test_set[\"weights\"][\n",
    "            test_set[\"labels\"] == 1\n",
    "        ] * (signal_weight / signal_weight_test)\n",
    "\n",
    "        train_set[\"weights\"][train_set[\"labels\"] == 0] = train_set[\"weights\"][\n",
    "            train_set[\"labels\"] == 0\n",
    "        ] * (background_weight / background_weight_train)\n",
    "        test_set[\"weights\"][test_set[\"labels\"] == 0] = test_set[\"weights\"][\n",
    "            test_set[\"labels\"] == 0\n",
    "        ] * (background_weight / background_weight_test)\n",
    "\n",
    "    return train_set, test_set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## The Model Class\n",
    "***\n",
    "We import a class named `Model` from the submission file (`model.py`). This `Model` class has the following methods:\n",
    "- `init`: receives train set and systematics class as input\n",
    "- `fit`: can be used for training\n",
    "- `predict`: receives one test set and outputs a dictionary with the following keys\n",
    "    - `mu_hat` : predicted mu $\\hat{\\mu}$\n",
    "    - `delta_mu_hat`: $\\Delta{\\hat{\\mu}}$ bound for $\\mu$\n",
    "    - `p16`: 16th percentile\n",
    "    - `p84`: 84th percentile\n",
    "\n",
    "In this example code, the `Model` class implements an XGBoost model which is trained to predict both the TES and the class label. You can find the code in `HEP-Challenge/sample_code_submission/model.py`. You can modify it the way you want, keeping the required class structure and functions there. More instructions are given inside the `model.py` file. If running in Collab, click the folder icon in the left sidebar to open the file browser.\n",
    "\n",
    "#### ⚠️ Note:\n",
    "In real setting i.e. the challenge itself, the submitted model is initialized once with train set and systematics class and the `predict` is called multiple times, each time with a different test sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_INTERNAL_ML_MODEL :\n",
    "    from xgboost import XGBClassifier\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    class Model:\n",
    "\n",
    "        def __init__(self, get_train_set=None, systematics=None):\n",
    "\n",
    "            self.get_train_set = get_train_set\n",
    "            self.systematics = systematics\n",
    "            self.re_train = True\n",
    "                    \n",
    "            self.model = XGBClassifier(eval_metric=[\"error\", \"logloss\", \"rmse\"],)\n",
    "            self.name = \"model_XGB\"\n",
    "            self.scaler = StandardScaler()\n",
    "            \n",
    "\n",
    "        def fit(self):\n",
    "            \"\"\"\n",
    "            Trains the model.\n",
    "\n",
    "            Params:\n",
    "                None\n",
    "\n",
    "            Functionality:\n",
    "                This function can be used to train a model. If `re_train` is True, it balances the dataset,\n",
    "                fits the model using the balanced dataset, and saves the model. If `re_train` is False, it\n",
    "                loads the saved model and calculates the saved information. The saved information is used\n",
    "                to compute the train results.\n",
    "\n",
    "            Returns:\n",
    "                None\n",
    "            \"\"\"\n",
    "\n",
    "\n",
    "            train_set = self.get_train_set() # train_set is a dictionary with data, labels, and weights\n",
    "            \n",
    "            training_set, holdout_set = train_test_split(\n",
    "                train_set, test_size=0.5, random_state=42, reweight=True\n",
    "            )\n",
    "            \n",
    "            del train_set\n",
    "            \n",
    "            training_set = self.systematics(training_set)\n",
    "\n",
    "            weights_train = training_set[\"weights\"].copy()\n",
    "            train_labels = training_set[\"labels\"].copy()\n",
    "            class_weights_train = (\n",
    "                weights_train[train_labels == 0].sum(),\n",
    "                weights_train[train_labels == 1].sum(),\n",
    "            )\n",
    "\n",
    "            for i in range(len(class_weights_train)):  # loop on B then S target\n",
    "                # training dataset: equalize number of background and signal\n",
    "                weights_train[train_labels == i] *= (\n",
    "                    max(class_weights_train) / class_weights_train[i]\n",
    "                )\n",
    "                # test dataset : increase test weight to compensate for sampling\n",
    "\n",
    "            training_set[\"weights\"] = weights_train\n",
    "                    \n",
    "            self.scaler.fit_transform(training_set[\"data\"])\n",
    "\n",
    "            X_train_data = self.scaler.transform(training_set[\"data\"])\n",
    "            self.model.fit(X_train_data,training_set[\"labels\"], training_set[\"weights\"])\n",
    "            \n",
    "            holdout_set = self.systematics(holdout_set)\n",
    "            \n",
    "            self.saved_info = calculate_saved_info(self.model, holdout_set)\n",
    "\n",
    "            holdout_score = self.model.predict(holdout_set[\"data\"])\n",
    "            holdout_results = compute_mu(\n",
    "                holdout_score, holdout_set[\"weights\"], self.saved_info\n",
    "            )\n",
    "                \n",
    "            print(\"Holdout Results: \")\n",
    "            for key in holdout_results.keys():\n",
    "                print(\"\\t\", key, \" : \", holdout_results[key])\n",
    "\n",
    "\n",
    "        def predict(self, test_set):\n",
    "            \"\"\"\n",
    "            Predicts the values for the test set.\n",
    "\n",
    "            Parameters:\n",
    "                test_set (dict): A dictionary containing the test data, and weights.\n",
    "\n",
    "            Returns:\n",
    "                dict: A dictionary with the following keys:\n",
    "                * 'mu_hat': The predicted value of mu.\n",
    "                * 'delta_mu_hat': The uncertainty in the predicted value of mu.\n",
    "                * 'p16': The lower bound of the 16th percentile of mu.\n",
    "                * 'p84': The upper bound of the 84th percentile of mu.\n",
    "            \"\"\"\n",
    "\n",
    "            test_data = test_set[\"data\"]\n",
    "            test_weights = test_set[\"weights\"]\n",
    "\n",
    "            test_data = self.scaler.transform(test_data)\n",
    "            predictions = self.model.predict_proba(test_data)[:, 1]\n",
    "        \n",
    "            result_mu_cal = compute_mu(predictions, test_weights, self.saved_info)\n",
    "\n",
    "            print(\"Test Results: \", result_mu_cal)\n",
    "\n",
    "            result = {\n",
    "                \"mu_hat\": result_mu_cal[\"mu_hat\"],\n",
    "                \"delta_mu_hat\": result_mu_cal[\"del_mu_tot\"],\n",
    "                \"p16\": result_mu_cal[\"mu_hat\"] - result_mu_cal[\"del_mu_tot\"],\n",
    "                \"p84\": result_mu_cal[\"mu_hat\"] + result_mu_cal[\"del_mu_tot\"],\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_INTERNAL_HISTOGRAM_MODEL :\n",
    "    import matplotlib.gridspec as gridspec\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    class Model:\n",
    "        def __init__(self, get_train_set=None, systematics=None):\n",
    "            \"\"\"\n",
    "            Parameters:\n",
    "            - get_train_set (function): A function that returns the training set.\n",
    "            - systematics (list): systematics paramter\n",
    "\n",
    "            Attributes:\n",
    "            - get_train_set (function): A function that returns the training set.\n",
    "            - systematics (list): A list of systematics.\n",
    "            - n_bins (int): Number of bins.\n",
    "            - mu_range (numpy array): Range of mu values.\n",
    "            - epsilon (float): A small value used for numerical stability.\n",
    "            - plot (bool): Flag indicating whether to plot the results.\n",
    "            \"\"\"\n",
    "            self.get_train_set = get_train_set\n",
    "            self.systematics = systematics\n",
    "\n",
    "            # Default values for other attributes\n",
    "            self.n_bins = 10\n",
    "            self.mu_range = np.linspace(0.001, 10.0, 400)\n",
    "            self.epsilon = 1e-20\n",
    "            self.plot = True\n",
    "            \n",
    "\n",
    "        def fit(self):\n",
    "            \"\"\"\n",
    "            Trains the model.\n",
    "\n",
    "            Params:\n",
    "                None\n",
    "\n",
    "            Functionality:\n",
    "                This function can be used to train a model. If `re_train` is True, it balances the dataset,\n",
    "                fits the model using the balanced dataset, and saves the model. If `re_train` is False, it\n",
    "                loads the saved model and calculates the saved information. The saved information is used\n",
    "                to compute the train results.\n",
    "\n",
    "            Returns:\n",
    "                None\n",
    "            \"\"\"\n",
    "\n",
    "            # Get the training set\n",
    "            train_set = self.get_train_set() # train_set is a dictionary with data, labels, and weights\n",
    "\n",
    "            # Apply systematics to the training set\n",
    "            train_set = systematics(train_set)\n",
    "            \n",
    "            # Separate the signal and background data and weights\n",
    "            data_sig = train_set[\"data\"].values[train_set[\"labels\"]==1, 0]\n",
    "            weights_sig = train_set[\"weights\"][train_set[\"labels\"]==1]\n",
    "\n",
    "            data_bkg = train_set[\"data\"].values[train_set[\"labels\"]==0, 0]\n",
    "            weights_bkg = train_set[\"weights\"][train_set[\"labels\"]==0]\n",
    "\n",
    "            # Set the bin range for histogram calculation\n",
    "            self.bin_range=(\n",
    "                1.05*min(np.min(data_sig), np.min(data_bkg)),\n",
    "                0.95*max(np.max(data_sig), np.max(data_bkg))\n",
    "            )\n",
    "            \n",
    "            # Calculate the signal template histogram\n",
    "            self.template_sig, _ = np.histogram(\n",
    "                data_sig,\n",
    "                weights=weights_sig,\n",
    "                range=self.bin_range, \n",
    "                bins=self.n_bins, \n",
    "                density=False\n",
    "            )\n",
    "            \n",
    "            # Calculate the background template histogram\n",
    "            self.template_bkg, _ = np.histogram(\n",
    "                data_bkg,\n",
    "                weights=weights_bkg,\n",
    "                range=self.bin_range, \n",
    "                bins=self.n_bins, \n",
    "                density=False\n",
    "            )\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "        def predict(self, test_set):\n",
    "            \"\"\"\n",
    "            Predicts the values for the test set.\n",
    "\n",
    "            Parameters:\n",
    "                test_set (dict): A dictionary containing the test data, and weights.\n",
    "\n",
    "            Returns:\n",
    "                dict: A dictionary with the following keys:\n",
    "                * 'mu_hat': The predicted value of mu.\n",
    "                * 'delta_mu_hat': The uncertainty in the predicted value of mu.\n",
    "                * 'p16': The lower bound of the 16th percentile of mu.\n",
    "                * 'p84': The upper bound of the 84th percentile of mu.\n",
    "            \"\"\"\n",
    "            # Convert test data and weights to numpy arrays, and select the first column of the data (Lepton_pt)\n",
    "            test_data = np.array(test_set[\"data\"])[:, 0]\n",
    "            test_weights = np.array(test_set[\"weights\"])[:]\n",
    "\n",
    "            # Calculate the histogram of test data\n",
    "            hist_test, _ = np.histogram(\n",
    "                test_data,\n",
    "                weights=test_weights,\n",
    "                range=self.bin_range, \n",
    "                bins=self.n_bins, \n",
    "                density=False\n",
    "            )        \n",
    "\n",
    "            # Initialize an array to store the negative log-likelihood values\n",
    "            nll2D = np.zeros((len(self.mu_range)))\n",
    "\n",
    "            # Iterate over mu values and calculate the negative log-likelihood\n",
    "            for mu_iter, mu_val in enumerate(self.mu_range):\n",
    "                N = hist_test + self.epsilon\n",
    "                nexp = mu_val * self.template_sig + self.template_bkg + self.epsilon\n",
    "\n",
    "                # Calculate the negative log-likelihood for fixed N, variable nexp\n",
    "                nll = - (N * np.log(nexp) - nexp)\n",
    "                nll2D[mu_iter] = np.sum(nll)\n",
    "\n",
    "            # Calculate the difference between the negative log-likelihood and its minimum value\n",
    "            nll_diff = nll2D-np.min(nll2D)\n",
    "            \n",
    "            # Create a mask to select only NLL values withing 4 of the minimum value for the fit\n",
    "            fitrange_mask = nll_diff < 4.0\n",
    "            \n",
    "            # Fit a parabola to the selected data points\n",
    "            z = np.polyfit(\n",
    "                self.mu_range[fitrange_mask], \n",
    "                nll_diff[fitrange_mask], \n",
    "                2,\n",
    "            )\n",
    "\n",
    "            poly = np.poly1d(z)\n",
    "\n",
    "            deriv1 = poly.deriv()\n",
    "            \n",
    "            # Find the minimum value of nll_diff and its corresponding mu value\n",
    "            min_mu_ind = np.argmin(nll_diff)\n",
    "            central = self.mu_range[min_mu_ind]\n",
    "\n",
    "            # Find the extrema of the polynomial and select the minimum value closest to the mu with the minimum nll_diff\n",
    "            extrema = (deriv1).roots\n",
    "            minimum = extrema[np.argsort(np.abs(extrema-central))][0]\n",
    "\n",
    "            # Find the intersections of the polynomial with the threshold value\n",
    "            # Threadhold 0.5 corresponds to 1 sigma in the chi2 distribution\n",
    "            threshold = .5\n",
    "            intersects = (poly - threshold).roots\n",
    "            \n",
    "            # Select 2 intersections closest to central value (only needed for polynomials with order > 2)\n",
    "            intersects = intersects[np.argsort(np.abs(intersects-central))][:2] \n",
    "\n",
    "            # Ensure first intersect is smaller than second intersect\n",
    "            intersects = np.sort(intersects)\n",
    "\n",
    "            # Plot the results if self.plot is True\n",
    "            if self.plot:\n",
    "                fig = plt.figure(figsize=(7,5))\n",
    "                outer = gridspec.GridSpec(1, 1, wspace=0.2, hspace=0.2)\n",
    "                subplot = fig.add_subplot(outer[0])\n",
    "\n",
    "                subplot.plot(self.mu_range, nll_diff, label='Nll_diff')\n",
    "                subplot.plot(self.mu_range, poly(self.mu_range), label='Fit')\n",
    "                subplot.set_ylim(-0.0, 4.5)\n",
    "\n",
    "                subplot.set_ylabel('NLL Difference')\n",
    "                subplot.set_xlabel('mu')\n",
    "\n",
    "                subplot.legend()\n",
    "                plt.show()\n",
    "\n",
    "            # Create a dictionary to store the results\n",
    "            result = {\n",
    "                \"mu_hat\": minimum,\n",
    "                \"delta_mu_hat\": abs(intersects[1] - intersects[0])/2,\n",
    "                \"p16\": intersects[0],\n",
    "                \"p84\": intersects[1],\n",
    "            }\n",
    "\n",
    "            return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you can defined you model you can submit it with the ingestion function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# initialize submission\n",
    "ingestion.init_submission(Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fit_submission` then calls fit method of the model and concludes the training phase of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fit submission\n",
    "ingestion.fit_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test set\n",
    "data.load_test_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST SETTINGS\n",
    "\n",
    "Here you can set the test settings. This will determine which all systematics are applied and how many pseudo experiments are run\n",
    "\n",
    "⚠️ Note: As you can see by default *tes* or *Tau-hadron Energy scale systematics* is applied, when running stat-only method turn this to `False` to get meaningfull results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_SETTINGS = {\n",
    "\"systematics\": {  # Systematics to use\n",
    "    \"tes\": True, # tau energy scale\n",
    "    \"jes\": False, # jet energy scale\n",
    "    \"soft_met\": False, # soft term in MET\n",
    "    \"ttbar_scale\": False, # ttbar scale factor\n",
    "    \"diboson_scale\": False, # diboson scale factor\n",
    "    \"bkg_scale\": False, # Background scale factor\n",
    "    },\n",
    "\"num_pseudo_experiments\" : 4 , # Number of pseudo-experiments to run per set\n",
    "\"num_of_sets\" : 3, # Number of sets of pseudo-experiments to run\n",
    "} \n",
    "\n",
    "USE_RANDOM_MUS = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_settings = TEST_SETTINGS.copy()\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "    \n",
    "if USE_RANDOM_MUS:\n",
    "    test_settings[ \"ground_truth_mus\"] = (np.random.uniform(0.1, 3, test_settings[\"num_of_sets\"])).tolist()\n",
    "    \n",
    "    random_settings_file = os.path.join(output_dir, \"random_mu.json\")\n",
    "    with open(random_settings_file, \"w\") as f:\n",
    "        json.dump(test_settings, f)\n",
    "else:\n",
    "    test_settings_file = os.path.join(input_dir, \"test\", \"settings\", \"data.json\")\n",
    "    with open(test_settings_file) as f:\n",
    "        test_settings = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is the prediction phase this is where the pseudo experiments are defined and the model is **repeatedly** called to Evalute each pseudo dataset. \n",
    "\n",
    "**⚠️ Note: In the Real Challenge the prediction step is parallelised.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# predict submission\n",
    "ingestion.predict_submission(test_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Last step combines the result from all the pseudo experiments and prepare it for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingestion.compute_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save result\n",
    "!rm -rf $output_dir/*\n",
    "ingestion.save_result(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Score\n",
    "***\n",
    "1. Compute Scores\n",
    "2. Visualize Scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from score import Scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Score\n",
    "score = Scoring()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.load_ingestion_results(output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next stage computes the score the submitted model by evaluting the results from ingestion.\n",
    "* Please note the plots show **average $\\mu$** and **NOT** the **true $\\mu$**. \n",
    "* Another plot is provided below exclusively for the starting kit with both the **average $\\mu$** and the **true $\\mu$.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Score\n",
    "score.compute_scores(test_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scatter plot of ground truth mu and predicted mu\n",
    "viz.visualize_scatter(ingestion_result_dict=ingestion.results_dict, \n",
    "                  ground_truth_mus=test_settings[\"ground_truth_mus\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize coverage\n",
    "viz.visualize_coverage(ingestion_result_dict=ingestion.results_dict, \n",
    "                  ground_truth_mus=test_settings[\"ground_truth_mus\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Submission\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prepare the submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipdir(archivename, basedir):\n",
    "    '''Zip directory, from J.F. Sebastian http://stackoverflow.com/'''\n",
    "    assert os.path.isdir(basedir)\n",
    "    with closing(ZipFile(archivename, \"w\", ZIP_DEFLATED)) as z:\n",
    "        for root, dirs, files in os.walk(basedir):\n",
    "            # NOTE: ignore empty directories\n",
    "            for fn in files:\n",
    "                if fn[-4:] != '.zip' and fn != '.DS_Store':\n",
    "                    absfn = os.path.join(root, fn)\n",
    "                    zfn = absfn[len(basedir):]  # XXX: relative path\n",
    "                    z.write(absfn, zfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (USE_INTERNAL_ML_MODEL or USE_INTERNAL_HISTOGRAM_MODEL):\n",
    "    the_date = datetime.datetime.now().strftime(\"%y-%m-%d-%H-%M\")\n",
    "    code_submission = 'Submission_' + the_date + '.zip'\n",
    "    zipdir(code_submission, submission_dir)\n",
    "    print(\"Submit : \" + code_submission + \" to the competition\")\n",
    "    print(\"You can find the zip file in `HEP-Challenge/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9e001b0608738f9411416229c98988c04b997dc526fb61c5e4e084e768e3249"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
